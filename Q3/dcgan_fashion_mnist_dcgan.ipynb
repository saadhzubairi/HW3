{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8a2c450",
   "metadata": {},
   "source": [
    "# DCGAN on FashionMNIST\n",
    "This notebook implements a Deep Convolutional GAN to generate synthetic FashionMNIST images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c21130",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8a4292",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision tqdm tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fcda65",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7df592",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    DATA_DIR    = \"data\"\n",
    "    OUTPUT_DIR  = \"outputs\"\n",
    "    LOG_DIR     = \"logs\"\n",
    "    IMG_SIZE    = 28\n",
    "    CHANNELS    = 1\n",
    "    LATENT_DIM  = 100\n",
    "    BATCH_SIZE  = 64\n",
    "    LR          = 1e-4\n",
    "    BETAS       = (0.5, 0.999)\n",
    "    EPOCHS      = 50\n",
    "    SAVE_EPOCHS = {10, 30, 50}\n",
    "    SEED        = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702c0a66",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b50751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eef4de9",
   "metadata": {},
   "source": [
    "## Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4b07f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(cfg):\n",
    "    tf = transforms.Compose([\n",
    "        transforms.Resize(cfg.IMG_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ])\n",
    "    ds = datasets.FashionMNIST(\n",
    "        root=cfg.DATA_DIR, train=True, download=True, transform=tf\n",
    "    )\n",
    "    return DataLoader(ds, batch_size=cfg.BATCH_SIZE, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7397b53",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c231f760",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        feat, slope, drop = 64, 0.3, 0.3\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(cfg.CHANNELS, feat, 5, 2, 2, bias=False),\n",
    "            nn.LeakyReLU(slope, inplace=True),\n",
    "            nn.Dropout(drop),\n",
    "            nn.Conv2d(feat, feat*2, 5, 2, 2, bias=False),\n",
    "            nn.LeakyReLU(slope, inplace=True),\n",
    "            nn.Dropout(drop),\n",
    "        )\n",
    "        ds = cfg.IMG_SIZE // 4\n",
    "        self.fc = nn.Linear(feat*2*ds*ds, 1, bias=False)\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return self.fc(x.view(x.size(0), -1)).view(-1)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        feat, slope = 64, 0.3\n",
    "        ds = cfg.IMG_SIZE // 4\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(cfg.LATENT_DIM, feat*4*ds*ds, bias=False),\n",
    "            nn.BatchNorm1d(feat*4*ds*ds),\n",
    "            nn.LeakyReLU(slope, inplace=True),\n",
    "        )\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.Unflatten(1, (feat*4, ds, ds)),\n",
    "            nn.ConvTranspose2d(feat*4, feat*2, 5, 2, 2, output_padding=1, bias=False),\n",
    "            nn.BatchNorm2d(feat*2),\n",
    "            nn.LeakyReLU(slope, inplace=True),\n",
    "            nn.ConvTranspose2d(feat*2, feat, 5, 2, 2, output_padding=1, bias=False),\n",
    "            nn.BatchNorm2d(feat),\n",
    "            nn.LeakyReLU(slope, inplace=True),\n",
    "            nn.ConvTranspose2d(feat, cfg.CHANNELS, 5, 1, 2, bias=False),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        x = self.fc(z)\n",
    "        return self.deconv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640aee28",
   "metadata": {},
   "source": [
    "## Initialization & Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7176925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.Linear)):\n",
    "        nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "\n",
    "def save_samples(gen, epoch, fixed_noise, cfg):\n",
    "    gen.eval()\n",
    "    with torch.no_grad():\n",
    "        imgs = gen(fixed_noise).add(1).div(2)\n",
    "        grid = make_grid(imgs, nrow=8)\n",
    "        os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "        save_image(grid, f\"{cfg.OUTPUT_DIR}/epoch_{epoch}.png\")\n",
    "    gen.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c89f3a",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360339e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(cfg):\n",
    "    torch.manual_seed(cfg.SEED)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    dl = get_dataloader(cfg)\n",
    "    gen = Generator(cfg).to(device)\n",
    "    disc = Discriminator(cfg).to(device)\n",
    "    gen.apply(weights_init); disc.apply(weights_init)\n",
    "    opt_g = optim.Adam(gen.parameters(), lr=cfg.LR, betas=cfg.BETAS)\n",
    "    opt_d = optim.Adam(disc.parameters(), lr=cfg.LR, betas=cfg.BETAS)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    fixed_noise = torch.randn(64, cfg.LATENT_DIM, device=device)\n",
    "    writer = SummaryWriter(cfg.LOG_DIR)\n",
    "    step = 0\n",
    "    for ep in range(1, cfg.EPOCHS+1):\n",
    "        for real, _ in tqdm(dl, desc=f\"Epoch {ep}/{cfg.EPOCHS}\"):\n",
    "            real = real.to(device); bs = real.size(0)\n",
    "            noise = torch.randn(bs, cfg.LATENT_DIM, device=device)\n",
    "            fake = gen(noise)\n",
    "            # Discriminator\n",
    "            opt_d.zero_grad()\n",
    "            d_real = disc(real)\n",
    "            d_fake = disc(fake.detach())\n",
    "            loss_d = criterion(d_real, torch.ones_like(d_real)) + criterion(d_fake, torch.zeros_like(d_fake))\n",
    "            loss_d.backward(); opt_d.step()\n",
    "            # Generator\n",
    "            opt_g.zero_grad()\n",
    "            d_fake2 = disc(fake)\n",
    "            loss_g = criterion(d_fake2, torch.ones_like(d_fake2))\n",
    "            loss_g.backward(); opt_g.step()\n",
    "            writer.add_scalar(\"Loss/Discriminator\", loss_d.item(), step)\n",
    "            writer.add_scalar(\"Loss/Generator\",     loss_g.item(), step)\n",
    "            step += 1\n",
    "        if ep in cfg.SAVE_EPOCHS:\n",
    "            save_samples(gen, ep, fixed_noise, cfg)\n",
    "    torch.save(gen.state_dict(), f\"{cfg.OUTPUT_DIR}/generator.pth\")\n",
    "    torch.save(disc.state_dict(), f\"{cfg.OUTPUT_DIR}/discriminator.pth\")\n",
    "    writer.close()\n",
    "\n",
    "cfg = Config()\n",
    "train(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20e60e5",
   "metadata": {},
   "source": [
    "## Generate Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c050b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(cfg, model_path=None, n=64):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    G = Generator(cfg).to(device)\n",
    "    mp = model_path or f\"{cfg.OUTPUT_DIR}/generator.pth\"\n",
    "    G.load_state_dict(torch.load(mp, map_location=device))\n",
    "    noise = torch.randn(n, cfg.LATENT_DIM, device=device)\n",
    "    save_samples(G, \"final\", noise, cfg)\n",
    "\n",
    "cfg = Config()\n",
    "generate(cfg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
